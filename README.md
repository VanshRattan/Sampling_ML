# ğŸ“˜ Sampling Assignment â€“ Credit Card Fraud Detection  
**Student ID:** 102316118  

---

## ğŸ“Œ Overview

This project evaluates how different **sampling techniques** affect the performance of
multiple **machine learning models** on an **imbalanced credit card fraud dataset**.

**Goals:**
- Handle class imbalance
- Apply different sampling techniques
- Compare model performance
- Identify the best sampling method

---

## ğŸ” Workflow


![alt text](image.png)

---

## âš–ï¸ Data Balancing

The dataset was highly imbalanced.  
The minority class (fraud cases) was **oversampled with replacement** until both classes were equal.
The balanced dataset was shuffled to avoid bias.

---

## ğŸ”„ Sampling Techniques

| Code | Technique |
|-----|----------|
| Sampling1 | Simple Random Sampling |
| Sampling2 | Stratified Sampling |
| Sampling3 | Bootstrap Sampling |
| Sampling4 | K-Fold Sampling |
| Sampling5 | Stratified K-Fold Sampling |

---

## ğŸ¤– Machine Learning Models

Logistic Regression, KNN, Decision Tree, Random Forest, and SVM were used for evaluation.

---

## ğŸ“ˆ Key Results

| Model | Best Sampling | Accuracy |
|------|--------------|----------|
| Logistic Regression | Sampling4 | 97.47% |
| KNN | Sampling1 | 96.86% |
| Decision Tree | Sampling1 | 97.94% |
| Random Forest | Sampling1 | 97.65% |
| SVM | Sampling1 | 96.55% |

---

## ğŸ† Best Sampling Technique

- **Overall Best:** Sampling1 (Simple Random Sampling)  
- **Exception:** Logistic Regression performs best with Sampling4  

---

## ğŸ§  Conclusion

After balancing the dataset, **Simple Random Sampling** worked best for most models.
Logistic Regression benefited from **K-Fold Sampling** due to its sensitivity to data splits.
This shows that the best sampling technique depends on the model.

---
